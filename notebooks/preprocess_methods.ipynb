{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa1a123-85b8-4827-b22f-50a4e2bf313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#installs\n",
    "!pip install nltk\n",
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install demoji\n",
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806362c9-5a19-4970-980e-d923e13b224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27143b0f-ce49-436c-9502-996a06ad5d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separates file names into comments vs submissions for each class\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "unpath = 'undiagnosed_user_data/'\n",
    "dpath = 'diagnosed_user_data/'\n",
    "unlist = os.listdir(unpath)\n",
    "dlist = os.listdir(dpath)\n",
    "dsubmissions = []\n",
    "dcomments = []\n",
    "usubmissions = []\n",
    "ucomments = []\n",
    "\n",
    "for file in dlist:\n",
    "    if '_submission_data.txt' in file:\n",
    "        dsubmissions.append(file)\n",
    "    elif '_comment_data.txt' in file:\n",
    "        dcomments.append(file)\n",
    "    else:\n",
    "        print(f'error with file: {file}')\n",
    "        continue\n",
    "        \n",
    "for file2 in unlist:\n",
    "    if '_submission_data.txt' in file2:\n",
    "        usubmissions.append(file2)\n",
    "    elif '_comment_data.txt' in file2:\n",
    "        ucomments.append(file2)\n",
    "    else:\n",
    "        print(f'error with file: {file2}')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c648f2f7-47c7-4dab-ab5d-db1ce059dc8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78163b5a-660b-49d2-817f-d1d1197b0a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing methods\n",
    "def submission_remove_lines(filename, name, isDiagnosed):\n",
    "    tempfile = open(filename, 'r')\n",
    "    front = ''\n",
    "    if isDiagnosed:\n",
    "        front += 'diagnosed_current/'\n",
    "    else:\n",
    "        front += 'undiagnosed_current/'\n",
    "    outfilename = '' + front + name + '_submissions_stripped.txt'\n",
    "    \n",
    "    outfile = open(outfilename, 'w')\n",
    "    for line in tempfile:\n",
    "        line_list = line.split(':;')\n",
    "        if len(line_list) != 15:\n",
    "            continue\n",
    "        if line_list[0] != name:\n",
    "            continue\n",
    "        \n",
    "        replacement_string = line.replace('\\n', ' ')\n",
    "        outfile.write(replacement_string.strip())\n",
    "        outfile.write('\\n')\n",
    "    tempfile.close()\n",
    "    outfile.close()\n",
    "        \n",
    "    return outfilename\n",
    "\n",
    "def comment_remove_lines(filename, name, isDiagnosed):\n",
    "    tempfile = open(filename, 'r')\n",
    "    front = ''\n",
    "    if isDiagnosed:\n",
    "        front += 'diagnosed_current/'\n",
    "    else:\n",
    "        front += 'undiagnosed_current/'\n",
    "    outfilename = '' + front + name + '_comments_stripped.txt'\n",
    "    outfile = open(outfilename, 'w')\n",
    "    for line in tempfile:\n",
    "        line_list = line.split(':;')\n",
    "        if len(line_list) != 12:\n",
    "            continue\n",
    "        if line_list[0] != name:\n",
    "            continue\n",
    "        replacement_string = line.replace('\\n', ' ')\n",
    "        \n",
    "        outfile.write(replacement_string.strip())\n",
    "        outfile.write('\\n')\n",
    "        \n",
    "    tempfile.close()\n",
    "    outfile.close()\n",
    "    return outfilename\n",
    "\n",
    "#returns 4 lists of filenames with files where extra spaces are removed,\n",
    "def preprocess_one(diagcoms, diagsubs, uncoms, unsubs):\n",
    "    diagnosed_comment_files = [] #keeps a list of filenames for diagnosed users\n",
    "    diagnosed_submission_files = [] #keeps a list of filenames for diagnosed users\n",
    "    undiagnosed_comment_files = [] #keeps a list of filenames for undiagnosed users\n",
    "    undiagnosed_submission_files = [] #keeps a list of filenames for undiagnosed users\n",
    "    for diag in diagcoms:\n",
    "        dfilename = 'diagnosed_user_data/' + diag\n",
    "        diagname = diag.split('_comment')[0]\n",
    "        currentfile = comment_remove_lines(dfilename, diagname, True)\n",
    "        newfname = 'demoji_diagnosed/' + currentfile.split('diagnosed_current/')[1]\n",
    "        currentfile = demoji_stuff(currentfile, newfname, True, False)\n",
    "        diagnosed_comment_files.append(currentfile)\n",
    "    \n",
    "        \n",
    "    for diag in diagsubs:\n",
    "        dfilename = 'diagnosed_user_data/' + diag\n",
    "        diagname = diag.split('_submission')[0]\n",
    "        currentfile= submission_remove_lines(dfilename, diagname, True)\n",
    "        newfname = 'demoji_diagnosed/' + currentfile.split('diagnosed_current/')[1]\n",
    "        currentfile = demoji_stuff(currentfile, newfname, True, True)\n",
    "        diagnosed_submission_files.append(currentfile)\n",
    "        \n",
    "        \n",
    "    for un in uncoms:\n",
    "        ufilename =  'undiagnosed_user_data/' + un\n",
    "        unname = un.split('_comment')[0]\n",
    "        currentfile = comment_remove_lines(ufilename, unname, False)\n",
    "        newfname = 'demoji_undiagnosed/' + currentfile.split('undiagnosed_current/')[1]\n",
    "        currentfile = demoji_stuff(currentfile, newfname, False, False)\n",
    "        undiagnosed_comment_files.append(currentfile)\n",
    "       \n",
    "    for un in unsubs:\n",
    "        ufilename =  'undiagnosed_user_data/' + un\n",
    "        unname = un.split('_submission')[0]\n",
    "        currentfile = submission_remove_lines(ufilename, unname, False)\n",
    "        newfname = 'demoji_undiagnosed/' + currentfile.split('undiagnosed_current/')[1]\n",
    "        currentfile = demoji_stuff(currentfile, newfname, False, True)\n",
    "        undiagnosed_submission_files.append(currentfile)\n",
    "        \n",
    "    #at this point all extra new line characters should be removed and demojied\n",
    "    \n",
    "    return diagnosed_comment_files, diagnosed_submission_files, undiagnosed_comment_files, undiagnosed_submission_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d7a106-56e7-4918-95ee-b8e3cf267dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing imports\n",
    "import os\n",
    "import demoji\n",
    "import re\n",
    "\n",
    "#done for now unless i want to incorporate emojis for deeper textual analysis\n",
    "#removes emojis from text posts, writes emoji counts to files: one for diagnosed, one for undiagnosed\n",
    "def demoji_stuff(filename, newfilename, isDiagnosed, isSubmission):\n",
    "    oldfile = open(filename, 'r')\n",
    "    newfile = open(newfilename, 'w')\n",
    "    emoji_count = 0\n",
    "    for line in oldfile:\n",
    "        emoji_count += len(demoji.findall_list(line))\n",
    "        templine = demoji.replace(line, \"\")#replaces all emojis with empty space, may change this to description later\n",
    "        newfile.write(templine.strip())\n",
    "        newfile.write('\\n')\n",
    "    oldfile.close()\n",
    "    newfile.close()\n",
    "    if isDiagnosed:\n",
    "        emojifile = open('emojis_diagnosed.txt', 'a')\n",
    "        if isSubmission:\n",
    "            name = newfilename.split('diagnosed/')[1].split('_submission')[0]\n",
    "        else:\n",
    "            name = newfilename.split('diagnosed/')[1].split('_comment')[0]\n",
    "        emojifile.write(str(name))\n",
    "        emojifile.write(':')\n",
    "        emojifile.write(str(emoji_count))\n",
    "        emojifile.write('\\n')\n",
    "        emojifile.close()\n",
    "    else:\n",
    "        if isSubmission:\n",
    "            name = newfilename.split('undiagnosed/')[1].split('_submission')[0]\n",
    "        else:\n",
    "            name = newfilename.split('undiagnosed/')[1].split('_comment')[0]\n",
    "        emojifile = open('emojis_undiagnosed.txt', 'a')\n",
    "        emojifile.write(str(name))\n",
    "        emojifile.write(':')\n",
    "        emojifile.write(str(emoji_count))\n",
    "        emojifile.write('\\n')\n",
    "        emojifile.close()\n",
    "    return newfilename\n",
    "\n",
    "def demoji2(dlist, ulist):\n",
    "    for user in dlist:\n",
    "        comm_filename = 'processed_diagnosed/' + user + '_comment_data.txt'\n",
    "        sub_filename = 'processed_diagnosed/' + user + '_submission_data.txt'\n",
    "        new_comm_filename = 'demoji_diagnosed/' + user +'_comments_stripped.txt'\n",
    "        new_sub_filename = 'demoji_diagnosed/' + user + '_submissions_stripped.txt'\n",
    "        \n",
    "        comm_file = open(comm_filename, 'r')\n",
    "        new_comm_file = open(new_comm_filename, 'w')\n",
    "        \n",
    "        for line in comm_file:\n",
    "            templine = demoji.replace(line, \"\")#replaces all emojis with empty space, may change this to description later\n",
    "            new_comm_file.write(templine.strip())\n",
    "            new_comm_file.write('\\n')\n",
    "        \n",
    "        comm_file.close()\n",
    "        new_comm_file.close()\n",
    "        \n",
    "        sub_file = open(sub_filename, 'r')\n",
    "        new_sub_file = open(new_sub_filename, 'w')\n",
    "        \n",
    "        for line in sub_file:\n",
    "            templine = demoji.replace(line, \"\")#replaces all emojis with empty space, may change this to description later\n",
    "            new_sub_file.write(templine.strip())\n",
    "            new_sub_file.write('\\n')\n",
    "        \n",
    "        sub_file.close()\n",
    "        new_sub_file.close()\n",
    "        \n",
    "    for user in ulist:\n",
    "        comm_filename = 'processed_undiagnosed/' + user + '_comment_data.txt'\n",
    "        sub_filename = 'processed_undiagnosed/' + user + '_submission_data.txt'\n",
    "        new_comm_filename = 'demoji_undiagnosed/' + user +'_comments_stripped.txt'\n",
    "        new_sub_filename = 'demoji_undiagnosed/' + user + '_submissions_stripped.txt'\n",
    "        comm_file = open(comm_filename, 'r')\n",
    "        new_comm_file = open(new_comm_filename, 'w')\n",
    "        \n",
    "        for line in comm_file:\n",
    "            templine = demoji.replace(line, \"\")#replaces all emojis with empty space, may change this to description later\n",
    "            new_comm_file.write(templine.strip())\n",
    "            new_comm_file.write('\\n')\n",
    "        \n",
    "        comm_file.close()\n",
    "        new_comm_file.close()\n",
    "        \n",
    "        sub_file = open(sub_filename, 'r')\n",
    "        new_sub_file = open(new_sub_filename, 'w')\n",
    "        \n",
    "        for line in sub_file:\n",
    "            templine = demoji.replace(line, \"\")#replaces all emojis with empty space, may change this to description later\n",
    "            new_sub_file.write(templine.strip())\n",
    "            new_sub_file.write('\\n')\n",
    "        \n",
    "        sub_file.close()\n",
    "        new_sub_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919e9996-c24a-4cc8-b23d-6068a850810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#removing whitespace from files\n",
    "def get_all_users():\n",
    "    all_uusers = []\n",
    "    all_dusers = []\n",
    "    \n",
    "    unanxietyfile = open('proven_all_diagnosed.txt', 'r')\n",
    "    for user in unanxietyfile:\n",
    "        all_dusers.append(user.strip())\n",
    "           \n",
    "    unanxietyfile2 = open('proven_all_undiagnosed.txt', 'r')\n",
    "    for user in unanxietyfile2:\n",
    "        all_uusers.append(user.strip())\n",
    "        \n",
    "    return all_dusers, all_uusers\n",
    "\n",
    "def remove_lines_comment(dusers, uusers):\n",
    "    for user in dusers:\n",
    "        filename = 'diagnosed_user_data/' + user + '_comment_data.txt'\n",
    "        fstring = open(filename).read().replace('\\n', ' ')\n",
    "        newname = 'processed_diagnosed/' + user + '_comment_data.txt'\n",
    "    \n",
    "        newfile = open(newname, 'w')\n",
    "        flist = fstring.split(':;')\n",
    "        \n",
    "        i = 1\n",
    "        for thing in flist:\n",
    "            if i % 12 == 0:\n",
    "                temp = thing.split()\n",
    "               # print(temp)\n",
    "                newfile.write(temp[0])\n",
    "                newfile.write('\\n')\n",
    "                if len(temp) > 1:\n",
    "                    newfile.write(temp[1])\n",
    "                    newfile.write(':;')\n",
    "                i+=1\n",
    "            else:\n",
    "                newfile.write(thing.rstrip())\n",
    "                newfile.write(':;')\n",
    "            i += 1\n",
    "        \n",
    "        newfile.close()\n",
    "        \n",
    "    for user in uusers:\n",
    "        filename = 'undiagnosed_user_data/' + user + '_comment_data.txt'\n",
    "        fstring = open(filename).read().replace('\\n', ' ')\n",
    "        newname = 'processed_undiagnosed/' + user + '_comment_data.txt'\n",
    "    \n",
    "        newfile = open(newname, 'w')\n",
    "        flist = fstring.split(':;')\n",
    "        \n",
    "        i = 1\n",
    "        for thing in flist:\n",
    "            if i % 12 == 0:\n",
    "                temp = thing.split()\n",
    "                #print(temp)\n",
    "                newfile.write(temp[0])\n",
    "                newfile.write('\\n')\n",
    "                if len(temp) > 1:\n",
    "                    newfile.write(temp[1])\n",
    "                    newfile.write(':;')\n",
    "                i+=1\n",
    "            else:\n",
    "                newfile.write(thing.rstrip())\n",
    "                newfile.write(':;')\n",
    "            i += 1\n",
    "        \n",
    "        newfile.close()\n",
    "def remove_lines_submission(dusers, uusers):\n",
    "    for user in dusers:\n",
    "        filename = 'diagnosed_user_data/' + user + '_submission_data.txt'\n",
    "        fstring = open(filename).read().replace('\\n', ' ')\n",
    "        newname = 'processed_diagnosed/' + user + '_submission_data.txt'\n",
    "    \n",
    "        newfile = open(newname, 'w')\n",
    "        flist = fstring.split(':;')\n",
    "        \n",
    "        i = 1\n",
    "        for thing in flist:\n",
    "            if i % 15 == 0:\n",
    "                temp = thing.split()\n",
    "                #print(temp)\n",
    "                \n",
    "                \n",
    "                if len(temp) > 1:\n",
    "                    for j in range(len(temp)-1):\n",
    "                        newfile.write(temp[j])\n",
    "                        newfile.write(' ')\n",
    "                    \n",
    "                    \n",
    "                    last_thing = temp[len(temp)-1]\n",
    "                    if last_thing.strip() == user.strip():\n",
    "                        newfile.write('\\n')\n",
    "                        newfile.write(temp[len(temp)-1])\n",
    "                        newfile.write(':;')\n",
    "                    else:\n",
    "                        newfile.write(temp[len(temp)-1])\n",
    "                        newfile.write('\\n')\n",
    "                    \n",
    "                else:\n",
    "                    newfile.write(temp[0])\n",
    "                    newfile.write('\\n')\n",
    "              #  print(temp[len(temp)-1])\n",
    "                i+=1\n",
    "            else:\n",
    "                newfile.write(thing.rstrip())\n",
    "                newfile.write(':;')\n",
    "            i += 1\n",
    "        \n",
    "        newfile.close()\n",
    "        \n",
    "    for user in uusers:\n",
    "        filename = 'undiagnosed_user_data/' + user + '_submission_data.txt'\n",
    "        fstring = open(filename).read().replace('\\n', ' ')\n",
    "        newname = 'processed_undiagnosed/' + user + '_submission_data.txt'\n",
    "        \n",
    "        newfile = open(newname, 'w')\n",
    "        flist = fstring.split(':;')\n",
    "        \n",
    "        i = 1\n",
    "        for thing in flist:\n",
    "            if i % 15 == 0:\n",
    "                temp = thing.split()\n",
    "                #print(temp)\n",
    "                \n",
    "                \n",
    "                if len(temp) > 1:\n",
    "                    for j in range(len(temp)-1):\n",
    "                        newfile.write(temp[j])\n",
    "                        newfile.write(' ')\n",
    "                    \n",
    "                    \n",
    "                    last_thing = temp[len(temp)-1]\n",
    "                    if last_thing.strip() == user.strip():\n",
    "                        newfile.write('\\n')\n",
    "                        newfile.write(temp[len(temp)-1])\n",
    "                        newfile.write(':;')\n",
    "                    else:\n",
    "                        newfile.write(temp[len(temp)-1])\n",
    "                        newfile.write('\\n')\n",
    "                    \n",
    "                else:\n",
    "                    newfile.write(temp[0])\n",
    "                    newfile.write('\\n')\n",
    "               # print(temp[len(temp)-1])\n",
    "                i+=1\n",
    "            else:\n",
    "                newfile.write(thing.rstrip())\n",
    "                newfile.write(':;')\n",
    "            i += 1\n",
    "        \n",
    "        \n",
    "        newfile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297eb479-68ed-413f-aea6-91f96112c727",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlist, ulist = get_all_users()\n",
    "remove_lines_comment(dlist,ulist)\n",
    "remove_lines_submission(dlist,ulist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb43ab67-855a-4725-b66f-f0021c33b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlist, ulist = get_all_users()\n",
    "demoji2(dlist, ulist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e53828c-0ae8-4349-9a8b-5b665e400c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dsubmissions = []\n",
    "#dcomments = []\n",
    "#usubmissions = []\n",
    "#ucomments = []\n",
    "dcomments2, dsubmissions2, ucomments2, usubmissions2 = preprocess_one(dcomments, dsubmissions, ucomments, usubmissions)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b3242b-6d24-4e59-aec1-b6720e5fcf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixes emoji files\n",
    "unemojifile = open('emojis_undiagnosed.txt','r')\n",
    "demojifile = open('emojis_diagnosed.txt', 'r')\n",
    "demojidict = {}\n",
    "unemojidict = {}\n",
    "\n",
    "for line in unemojifile:\n",
    "    temp = line.split(':')\n",
    "    if len(temp) != 2:\n",
    "        print(f'error with {line}')\n",
    "        continue\n",
    "    name = temp[0]\n",
    "    count = int(temp[1])\n",
    "    if name in unemojidict:\n",
    "        unemojidict[name] += count\n",
    "    else:\n",
    "        unemojidict[name] = count\n",
    "for line in demojifile:\n",
    "    temp = line.split(':')\n",
    "    if len(temp) != 2:\n",
    "        print(f'error with {line}')\n",
    "        continue\n",
    "    name = temp[0]\n",
    "    count = int(temp[1])\n",
    "    if name in demojidict:\n",
    "        demojidict[name] += count\n",
    "    else:\n",
    "        demojidict[name] = count\n",
    "unemojifile.close()\n",
    "demojifile.close()\n",
    "\n",
    "unemojiout = open('emojis_undiagnosed_unique.txt', 'w')\n",
    "demojiout = open('emojis_diagnosed_unique.txt', 'w')\n",
    "for name in unemojidict:\n",
    "    unemojiout.write(name)\n",
    "    unemojiout.write(':')\n",
    "    unemojiout.write(str(unemojidict[name]))\n",
    "    unemojiout.write('\\n')\n",
    "for name in demojidict:\n",
    "    demojiout.write(name)\n",
    "    demojiout.write(':')\n",
    "    demojiout.write(str(demojidict[name]))\n",
    "    demojiout.write('\\n')\n",
    "unemojiout.close()\n",
    "demojiout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ead7790-dddd-4a0b-9fdf-f4e8f84f97cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#emoji distributions\n",
    "def emoji_distributions():\n",
    "   \n",
    "    undiagnosed_emojis = []\n",
    "    diagnosed_emojis = []\n",
    "\n",
    "    unemojifile = open('emojis_undiagnosed_unique.txt','r')\n",
    "    demojifile = open('emojis_diagnosed_unique.txt', 'r')\n",
    "\n",
    "    for line in unemojifile:\n",
    "        temp = line.split(':')\n",
    "        if len(temp) != 2:\n",
    "            print(f'error with {line}')\n",
    "            continue\n",
    "        undiagnosed_emojis.append(int(temp[1]))\n",
    "    for line in demojifile:\n",
    "        temp = line.split(':')\n",
    "        if len(temp) != 2:\n",
    "            print(f'error with {line}')\n",
    "            continue\n",
    "        \n",
    "        diagnosed_emojis.append(int(temp[1]))\n",
    "\n",
    "    unemojifile.close()\n",
    "    demojifile.close()\n",
    "    return diagnosed_emojis, undiagnosed_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40159a9f-7a83-41fb-bb1e-300a3633d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "demoji_list, unmoji_list = emoji_distributions()\n",
    "plt.hist(demoji_list, range = (0, 600))\n",
    "#plt.hist(unmoji_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b08742-e111-41c6-945e-38579dd29c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp cell to find users who i have data on and print that list to a file / store it in a list\n",
    "\n",
    "dpath = 'demoji_diagnosed/'\n",
    "upath = 'demoji_undiagnosed/'\n",
    "\n",
    "unlist = os.listdir(unpath)\n",
    "dlist = os.listdir(dpath)\n",
    "\n",
    "print(len(unlist))\n",
    "print(len(dlist))\n",
    "\n",
    "duser_list = []\n",
    "uuser_list = []\n",
    "ufilename = 'current_undiagnosed_users.csv'\n",
    "ufile = open(ufilename, 'w')\n",
    "for user in unlist:\n",
    "    if '_submission' in user:\n",
    "        name = user.split('_submission')[0]\n",
    "    elif '_comment' in user:\n",
    "        name = user.split('_comment')[0]\n",
    "    else:\n",
    "        print(f'error on {user}')\n",
    "        continue\n",
    "    if name in uuser_list:\n",
    "        continue\n",
    "    else:\n",
    "        uuser_list.append(name)\n",
    "        ufile.write(str(name))\n",
    "        ufile.write(':;')\n",
    "ufile.close()\n",
    "\n",
    "dfilename = 'current_diagnosed_users.csv'\n",
    "dfile = open(dfilename, 'w')\n",
    "for user in dlist:\n",
    "    if '_submission' in user:\n",
    "        name = user.split('_submission')[0]\n",
    "    elif '_comment' in user:\n",
    "        name = user.split('_comment')[0]\n",
    "    else:\n",
    "        print(f'error on {user}')\n",
    "        continue\n",
    "    if name in duser_list:\n",
    "        continue\n",
    "    else:\n",
    "        duser_list.append(name)\n",
    "        dfile.write(str(name))\n",
    "        dfile.write(':;')\n",
    "dfile.close()\n",
    "\n",
    "print(f'number of diagnosed users currently: {len(duser_list)}')\n",
    "print(f'number of undiagnosed users currently {len(uuser_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a749992-75fb-47c4-93a4-10cc18fee8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3738 undiagnosed files\n",
    "#15672 diagnosed files\n",
    "#9954 diagnosed users\n",
    "#1870 undiagnosed users\n",
    "unpath = 'undiagnosed_user_data/'\n",
    "dpath = 'diagnosed_user_data/'\n",
    "dpath2 = 'diagnosed_current/'\n",
    "unpath2 = 'undiagnosed_current/'\n",
    "dpath3 = 'demoji_diagnosed/'\n",
    "unpath3 = 'demoji_undiagnosed/'\n",
    "\n",
    "unlist1 = os.listdir(unpath)\n",
    "dlist1 = os.listdir(dpath)\n",
    "unlist2 = os.listdir(unpath2)\n",
    "dlist2 = os.listdir(dpath2)\n",
    "unlist3 = os.listdir(unpath3)\n",
    "dlist3 = os.listdir(dpath3)\n",
    "\n",
    "print(f'first undiagnosed count: {len(unlist1)}')\n",
    "print(f'first diagnosed count: {len(dlist1)}')\n",
    "print(f'second undiagnosed count: {len(unlist2)}')\n",
    "print(f'second diagnosed count: {len(dlist2)}')\n",
    "print(f'third undiagnosed count: {len(unlist3)}')\n",
    "print(f'third diagnosed count: {len(dlist3)}')\n",
    "\n",
    "print(len(dsubmissions))\n",
    "print(len(dcomments))\n",
    "print(f'combined diagnosed: {len(dsubmissions) + len(dcomments)}')\n",
    "print(len(usubmissions))\n",
    "print(len(ucomments))\n",
    "print(f'combined undiagnosed: {len(usubmissions) + len(ucomments)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c2c93d-c1f8-41c3-aa1b-4813899270da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "def remove_whitespaces(line):\n",
    "    return \" \".join(line.split())\n",
    "\n",
    "def spell_correction(text):\n",
    "    wordlist = text.split()\n",
    "    corrected_wordlist = []\n",
    "    checker = SpellCheck()\n",
    "    for word in wordlist:\n",
    "        correct = checker.correction(word)\n",
    "        corrected_wordlist.append(correct)\n",
    "    return \" \".join(corrected_wordlist)\n",
    "\n",
    "def stemming(text):\n",
    "    wordlist = text.split()\n",
    "    corrected_wordlist = []\n",
    "    porter = PorterStemmer()\n",
    "    for word in wordlist:\n",
    "        correct = porter.stem(word)\n",
    "        corrected_wordlist.append(correct)\n",
    "    return \" \".join(corrected_wordlist)\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "def remove_punct(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def preprocessv1(text):\n",
    "    text = remove_urls(text)\n",
    "    text = remove_punct(text)\n",
    "    text = remove_whitespaces(text) #removing extra white spaces\n",
    "    text = text.lower() #lowercasing\n",
    "    \n",
    "    return text\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014745c-27a0-4a11-821d-60a7eee7019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas part 1, make a dataframe with username: combined text\n",
    "\n",
    "dpath3 = 'demoji_diagnosed/'\n",
    "unpath3 = 'demoji_undiagnosed/'\n",
    "drawframe = pd.DataFrame()\n",
    "drawdict = {}\n",
    "urawframe = pd.DataFrame()\n",
    "urawdict = {}\n",
    "unlist3 = os.listdir(unpath3)\n",
    "dlist3 = os.listdir(dpath3)\n",
    "\n",
    "for username in unlist3:\n",
    "    filename = 'demoji_undiagnosed/' + username\n",
    "    demojifile = open(filename, 'r')\n",
    "    if '_submission' in username:\n",
    "        for line in demojifile:\n",
    "            linelist = line.split(':;')\n",
    "            if len(linelist) != 15:\n",
    "                continue\n",
    "            author = linelist[0]\n",
    "            selftext = linelist[9]\n",
    "            selftext += ' '\n",
    "            selftext += linelist[14]\n",
    "            selftext = preprocessv1(selftext)\n",
    "            if author in urawdict:\n",
    "                urawdict[author] += ' ' + selftext\n",
    "                urawframe[author] += ' ' + selftext\n",
    "            else:\n",
    "                urawdict[author] = selftext\n",
    "                urawframe[author] = selftext\n",
    "                \n",
    "    elif '_comment' in username:\n",
    "        for line in demojifile:\n",
    "            linelist = line.split(':;')\n",
    "            if len(linelist) != 12:\n",
    "                continue\n",
    "            author = linelist[0]\n",
    "            body = linelist[2]\n",
    "            body = preprocessv1(body)\n",
    "            if author in urawdict:\n",
    "                urawdict[author] += ' ' + body\n",
    "                urawframe[author] += ' ' + body\n",
    "            else:\n",
    "                urawdict[author] = body\n",
    "                urawframe[author] = body\n",
    "    \n",
    "for username in dlist3:\n",
    "    filename = 'demoji_diagnosed/' + username\n",
    "    demojifile = open(filename, 'r')\n",
    "    \n",
    "    if '_submission' in username:\n",
    "        for line in demojifile:\n",
    "            linelist = line.split(':;')\n",
    "            if len(linelist) != 15:\n",
    "                continue\n",
    "            author = linelist[0]\n",
    "            selftext = linelist[9]\n",
    "            selftext += ' '\n",
    "            selftext += linelist[14]\n",
    "            selftext = preprocessv1(selftext)\n",
    "            if author in drawdict:\n",
    "                drawdict[author] += ' ' + selftext\n",
    "                drawframe[author] += ' ' + selftext \n",
    "            else:\n",
    "                drawdict[author] = selftext\n",
    "                drawframe[author] = selftext\n",
    "    elif '_comment' in username:\n",
    "        for line in demojifile:\n",
    "            linelist = line.split(':;')\n",
    "            if len(linelist) != 12:\n",
    "                continue\n",
    "            author = linelist[0]\n",
    "            body = linelist[2]\n",
    "            body = preprocessv1(body)\n",
    "            if author in drawdict:\n",
    "                drawdict[author] += ' ' + body\n",
    "                drawfame[author] += ' ' + body\n",
    "            else:\n",
    "                drawdict[author] = body\n",
    "                drawframe[author] = body\n",
    "    \n",
    "                \n",
    "ddictframe = pd.DataFrame(drawdict)\n",
    "udictframe = pd.DataFrame(urawdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7873156f-b994-42b9-820d-508f0d63c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diagnosed part only\n",
    "dpath3 = 'demoji_diagnosed/'\n",
    "drawframe = pd.DataFrame()\n",
    "drawdict = {}\n",
    "dlist3 = os.listdir(dpath3)\n",
    "\n",
    "\n",
    "for username in dlist3:\n",
    "    filename = 'demoji_diagnosed/' + username\n",
    "    demojifile = open(filename, 'r')\n",
    "    \n",
    "    if '_submission' in username:\n",
    "        for line in demojifile:\n",
    "            linelist = line.split(':;')\n",
    "            if len(linelist) != 15:\n",
    "               \n",
    "                continue\n",
    "            author = linelist[0]\n",
    "            selftext = linelist[9]\n",
    "            selftext += ' '\n",
    "            selftext += linelist[14]\n",
    "            selftext = preprocessv1(selftext)\n",
    "            if author in drawdict:\n",
    "                drawdict[author] += ' ' + selftext\n",
    "               # drawframe[author] += ' ' + selftext \n",
    "            else:\n",
    "                drawdict[author] = selftext\n",
    "                #drawframe[author] = selftext\n",
    "    elif '_comment' in username:\n",
    "        for line in demojifile:\n",
    "            linelist = line.split(':;')\n",
    "            if len(linelist) != 12:\n",
    "               \n",
    "                continue\n",
    "            author = linelist[0]\n",
    "            body = linelist[2]\n",
    "            body = preprocessv1(body)\n",
    "            if author in drawdict:\n",
    "                drawdict[author] += ' ' + body\n",
    "                #drawframe[author] += ' ' + body\n",
    "            else:\n",
    "                drawdict[author] = body\n",
    "               # drawframe[author] = body\n",
    "\n",
    "                \n",
    "#ddictframe = pd.DataFrame(drawdict)\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9d6415-65f0-47af-84f9-7c2379714211",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddictframe = pd.DataFrame(drawdict, index = [0])\n",
    "ddictframe = ddictframe.transpose()\n",
    "print(ddictframe.head())\n",
    "ddictframe.to_csv('ddframe.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569f2f7-bf9d-4d44-a536-7c63c6e32026",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dlist3))\n",
    "print(len(ddictframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cc6955-2535-4b1c-9613-d00579f77082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diagnosed part only retrieves subreddits\n",
    "dpath3 = 'demoji_diagnosed/'\n",
    "dlist3 = os.listdir(dpath3)\n",
    "\n",
    "dusers_persub = {}\n",
    "dposts_persub = {}\n",
    "dwordcounts_persub = {}\n",
    "processed_subs = [] #stores a list of initialized subs so i dont have to check each dict\n",
    "\n",
    "for username in dlist3:\n",
    "    filename = 'demoji_diagnosed/' + username\n",
    "    demojifile = open(filename, 'r')\n",
    "    \n",
    "    if '_submission' in username:\n",
    "        for line in demojifile:\n",
    "            linelist = line.split(':;')\n",
    "            if len(linelist) != 15:\n",
    "               \n",
    "                continue\n",
    "            user = linelist[0]\n",
    "            selftext = linelist[9]\n",
    "            selftext += ' '\n",
    "            selftext += linelist[14]\n",
    "            selftext = preprocessv1(selftext)\n",
    "            subreddit = linelist[10]\n",
    "            wordcount = len(selftext.split(' '))\n",
    "            \n",
    "            \n",
    "            if subreddit in processed_subs:\n",
    "                dposts_persub[subreddit] += 1\n",
    "                dwordcounts_persub[subreddit] += wordcount\n",
    "                \n",
    "                if user in dusers_persub[subreddit]:\n",
    "                    dusers_persub[subreddit][user] += 1\n",
    "                else:\n",
    "                    dusers_persub[subreddit][user] = 1\n",
    "            else:\n",
    "                dposts_persub[subreddit] = 1\n",
    "                dwordcounts_persub[subreddit] = wordcount\n",
    "                dusers_persub[subreddit] = {}\n",
    "                dusers_persub[subreddit][user] = 1\n",
    "                processed_subs.append(subreddit)\n",
    "           \n",
    "    elif '_comment' in username:\n",
    "        for line in demojifile:\n",
    "            linelist = line.split(':;')\n",
    "            if len(linelist) != 12:\n",
    "               \n",
    "                continue\n",
    "            user = linelist[0]\n",
    "            body = linelist[2]\n",
    "            body = preprocessv1(body)\n",
    "            subreddit = linelist[9]\n",
    "            wordcount = len(body.split(' '))\n",
    "           \n",
    "            if subreddit in processed_subs:\n",
    "                dposts_persub[subreddit] += 1\n",
    "                dwordcounts_persub[subreddit] += wordcount\n",
    "                \n",
    "                if user in dusers_persub[subreddit]:\n",
    "                    dusers_persub[subreddit][user] += 1\n",
    "                else:\n",
    "                    dusers_persub[subreddit][user] = 1\n",
    "            else:\n",
    "                dposts_persub[subreddit] = 1\n",
    "                dwordcounts_persub[subreddit] = wordcount\n",
    "                dusers_persub[subreddit] = {}\n",
    "                dusers_persub[subreddit][user] = 1\n",
    "                processed_subs.append(subreddit)\n",
    "           \n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621b290d-bafb-4caa-b2f5-dac6bff8f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diagnosed part only retrieves subreddits with users\n",
    "dpath3 = 'demoji_diagnosed/'\n",
    "dlist3 = os.listdir(dpath3)\n",
    "\n",
    "dusers_persub = {}\n",
    "processed_subs = [] #stores a list of initialized subs so i dont have to check each dict\n",
    "processed_users = {} #one list per sub\n",
    "\n",
    "for username in dlist3:\n",
    "    filename = 'demoji_diagnosed/' + username\n",
    "    demojifile = open(filename, 'r')\n",
    "    \n",
    "    if '_submission' in username:\n",
    "        for line in demojifile:\n",
    "            linelist = line.split(':;')\n",
    "            if len(linelist) != 15:\n",
    "                continue\n",
    "            user = linelist[0]\n",
    "            subreddit = linelist[10]\n",
    "            \n",
    "            if subreddit in processed_subs:\n",
    "                if not user in processed_users[subreddit]:\n",
    "                \n",
    "                    dusers_persub[subreddit] += 1\n",
    "                    processed_users[subreddit].append(user)\n",
    "                \n",
    "            else:\n",
    "                processed_subs.append(subreddit)\n",
    "                dusers_persub[subreddit] = 1\n",
    "                processed_users[subreddit] = []\n",
    "                processed_users[subreddit].append(user)\n",
    "                \n",
    "           \n",
    "    elif '_comment' in username:\n",
    "        for line in demojifile:\n",
    "            linelist = line.split(':;')\n",
    "            if len(linelist) != 12:\n",
    "               \n",
    "                continue\n",
    "            user = linelist[0]\n",
    "           \n",
    "            subreddit = linelist[9]\n",
    "          \n",
    "           \n",
    "            if subreddit in processed_subs:\n",
    "                if not user in processed_users[subreddit]:\n",
    "                    dusers_persub[subreddit] += 1\n",
    "                    processed_users[subreddit].append(user)\n",
    "                \n",
    "            else:\n",
    "                processed_subs.append(subreddit)\n",
    "                dusers_persub[subreddit] = 1\n",
    "                processed_users[subreddit] = []\n",
    "                processed_users[subreddit].append(user)\n",
    "           \n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aa67fa-21ac-4ca6-bf4b-1c3ee5db2cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpostframe = pd.DataFrame(dposts_persub, index = [0])\n",
    "dpostframe = dpostframe.transpose()\n",
    "dpostframe.to_csv('dpostframe.csv', sep = ';')\n",
    "print(dpostframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea8e8b1-8543-4690-a2f0-52950a56387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwordframe = pd.DataFrame(dwordcounts_persub, index = [0])\n",
    "dwordframe = dwordframe.transpose()\n",
    "dwordframe.to_csv('dwordframe.csv', sep = ';')\n",
    "print(dwordframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d15334e-04a2-4b01-b146-7550086332cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dwordcount_persub))\n",
    "print(len(dposts_persub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0e0260-42d7-4a48-b8a7-68167829630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "duserframe = pd.DataFrame(dusers_persub, index = [0])\n",
    "#duserframe = duserframe.transpose()\n",
    "duserframe.to_csv('duserframe.csv', sep = ';')\n",
    "print(duserframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993af173-3114-4e11-8142-60f29e469b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "res = dict(sorted(dusers_persub.items(), key = itemgetter(1), reverse = True)[100:200])\n",
    "tempfile = open('dusers100to200.csv', 'w')\n",
    "for name in res:from operator import itemgetter\n",
    "res = dict(sorted(dusers_persub.items(), key = itemgetter(1), reverse = True)[100:200])\n",
    "tempfile = open('dusers100to200.csv', 'w')\n",
    "for name in res:\n",
    "    tempfile.write(str(name))\n",
    "    tempfile.write(';')\n",
    "    tempfile.write(str(res[name]))\n",
    "    tempfile.write('\\n')\n",
    "tempfile.close()\n",
    "    tempfile.write(str(name))\n",
    "    tempfile.write(';')\n",
    "    tempfile.write(str(res[name]))\n",
    "    tempfile.write('\\n')\n",
    "tempfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b24dbd-7b8d-4243-9684-59c7b816577e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dbade4-bcab-48a6-af81-bb35fa478490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_text(filename):\n",
    "    csvfilename = '' + filename + '.csv'\n",
    "    clonefilename = '' + filename + '.txt'\n",
    "    csvfile = open(csvfilename, 'r')\n",
    "    clonefile = open(clonefilename, 'w')\n",
    "    for line in csvfile:\n",
    "        clonefile.write(line.strip())\n",
    "        clonefile.write(';')\n",
    "        clonefile.write('\\n')\n",
    "    csvfile.close()\n",
    "    clonefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e04505-f308-4bd7-ad41-b9f8980cd384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv_to_text('dposts')\n",
    "csv_to_text('dusers100to200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09529334-a225-49ae-9916-1e5632a65493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stemmed_data(extension):\n",
    "    dfilename = 'dstemmed_' + extension + '.txt'\n",
    "    ufilename = 'ustemmed_' + extension + '.txt'\n",
    "    \n",
    "    ddict = {}\n",
    "    udict = {}\n",
    "    \n",
    "    dfile = open(dfilename,'r')\n",
    "    ufile = open(ufilename,'r')\n",
    "    \n",
    "    for line in dfile:\n",
    "        line_list = line.split(':;')\n",
    "        if len(line_list) != 2:\n",
    "            print('error')\n",
    "            break\n",
    "        ddict[line_list[0]] = line_list[1].strip() \n",
    "    \n",
    "    for line in ufile:\n",
    "        line_list = line.split(':;')\n",
    "        if len(line_list) != 2:\n",
    "            print('error')\n",
    "            break\n",
    "        udict[line_list[0]] = line_list[1].strip() \n",
    "    \n",
    "    dfile.close()\n",
    "    ufile.close()\n",
    "    \n",
    "    return ddict, udict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481a0fc5-5d94-45e8-b683-daf034fd03ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_fasttext_file(extension):\n",
    "    ddict, udict = get_stemmed_data(extension)\n",
    "    newfilename = 'fasttext_' + extension + '.txt'\n",
    "    newfile = open(newfilename, 'w')\n",
    "    for user in ddict:\n",
    "        label = '__label__diagnosed'\n",
    "        newfile.write(str(ddict[user]).strip())\n",
    "        newfile.write(' ')\n",
    "        newfile.write(label)\n",
    "        newfile.write('\\n')\n",
    "        \n",
    "    for user in udict:\n",
    "        label = '__label__undiagnosed'\n",
    "        newfile.write(str(ddict[user]).strip())\n",
    "        newfile.write(' ')\n",
    "        newfile.write(label)\n",
    "        newfile.write('\\n')\n",
    "    \n",
    "    newfilename.close()\n",
    "def split_fasttext_file(extension, test_decimal):\n",
    "    basefilename = 'fasttext_' + extension + '.txt'\n",
    "    basefile = open(basefilename, 'r')\n",
    "    baselist = list(basefile.readlines())\n",
    "    basefile.close()\n",
    "    np.random.shuffle(baselist)\n",
    "    trainfilename = 'fasttext_' + extension + 'train.txt'\n",
    "    testfilename = 'fasttext_' + extension + 'test.txt'\n",
    "    \n",
    "    split_index = (1.0-test_decimal) * len(baselist)\n",
    "    train_split = baselist[::split_index-1]\n",
    "    test_split = baselist[split_index::]\n",
    "    \n",
    "    trainfile = open(trainfilename, 'w')\n",
    "    for line in train_split:\n",
    "        trainfile.write(str(train_split[line]).strip())\n",
    "        trainfile.write('\\n')\n",
    "    trainfile.close()\n",
    "    \n",
    "    testfile = open(testfilename, 'w')\n",
    "    for line in test_split:\n",
    "        testfile.write(str(test_split[line]).strip())\n",
    "        testfile.write('\\n')\n",
    "    testfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f32e79-e946-4af1-bce7-a5f6231b0c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
